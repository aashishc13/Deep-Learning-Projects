# -*- coding: utf-8 -*-
"""Project_2_ASHISH_CHANDRA_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19tufaPZtHHHDuimd53xROmNKnH6d5eOE

#Student Name: ASHISH CHANDRA
#ECE 595 Machine Learning II
#Project 2: Autoencoders - Student Code
"""

# The D-dimensional noise vector length
latent_dim = 100

# Optimizer for discriminator, which will have a higher learning rate than adversarial model

def dis_optimizer():
    #return adam(lr = 0.0002, beta_1 = 0.9, beta_2 = 0.999)
    return adam(lr = 0.0002, beta_1 = 0.5)

def gan_optimizer():
    #return adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999)
    return adam(lr = 0.0002, beta_1 = 0.5) 




# Genrerator model
dim = 7
depth = 64+64+64+64 #256
def create_generator():
    generator = Sequential()
    generator.add(Dense(depth, input_dim = latent_dim))
    generator.add(LeakyReLU(alpha = 0.2))

    generator.add(Dense(512))
    generator.add(LeakyReLU(alpha = 0.2))

    generator.add(Dense(1024))
    generator.add(LeakyReLU(alpha = 0.2))

    generator.add(Dense(28*28, activation = 'tanh'))

    #generator.compile(loss = keras.losses.BinaryCrossentropy(),
    #                      optimizer = gan_optimizer(),
    #                      metrics = ['accuracy'])
    return generator

# Discriminator model
def create_discriminator():
    discriminator = Sequential()
    discriminator.add(Dense(1024, input_dim = 28*28))
    discriminator.add(LeakyReLU(alpha = 0.2))
    
    discriminator.add(Dropout(0.30)) #0.25

    discriminator.add(Dense(512))
    discriminator.add(LeakyReLU(alpha = 0.2))
    
    discriminator.add(Dropout(0.30)) #0.25

    discriminator.add(Dense(256))
    discriminator.add(LeakyReLU(alpha = 0.2))

    discriminator.add(Dense(units = 1, activation = 'sigmoid'))
    discriminator.compile(loss = keras.losses.BinaryCrossentropy(),
                          optimizer = dis_optimizer(),
                          metrics = ['accuracy'])
    return discriminator

# Create adversarial model
def create_gan(discriminator, generator):
    discriminator.trainable = False
    gan_input = Input(shape=(latent_dim,))
    x = generator(gan_input)
    gan_output = discriminator(x)
    gan = Model(inputs = gan_input, outputs = gan_output)
    gan.compile(loss = keras.losses.BinaryCrossentropy(),
                optimizer = gan_optimizer(),
                metrics = ['accuracy'])
    return gan

# Creating graph for GAN
generator = create_generator()
discriminator = create_discriminator()
gan = create_gan(discriminator, generator)



# ALGORITHM 1
# Model and training parameters
#ASSIGN VALUES TO THE FOLLOWING VARIABLES
epochs = 10000          # debug using small epochs 5
batch_size = 1024 
sample_interval = 10000      # debug using small interval 1

plot_loss_descriminator = []
plot_acc_descriminator = []
plot_loss_gan = []
plot_acc_gan = []

# Array to save training history
training_meta_data = np.zeros([epochs, 4])

# Training the GAN
for e in range(1, epochs+1):

    # Generate random noise as input
    noise = np.random.normal(0,1, size = (batch_size, latent_dim)) #-0.10

    # Generate fake MNIST images from generated noise
    fake_image = generator.predict(noise)
    #print("fake image shape :", fake_image.shape)

    # Get a random set of real MNIST images
    real_image = data_train[np.random.randint(0, data_train.shape[0], size = batch_size)]
    real_image = real_image.reshape(batch_size, 28*28)
    #print(" Real image shape :", real_image.shape)

    # Concatenate real and fake images into a single array (or batch)
    data_total = np.concatenate([real_image, fake_image])

    # Assign training labels (assign high probability, but not 1, to real images)
    labels_real = np.ones((batch_size))*0.9
    labels_fake = np.zeros((batch_size)) #0.10 
    labels_dis = np.concatenate([labels_real, labels_fake])

    # Allow discriminator parameters to be updated
    discriminator.trainable = True

    # Train discriminator on batch of real and fake images. Assign loss and accuracy to variable
    d_loss = discriminator.train_on_batch(data_total, labels_dis)
    plot_loss_descriminator.append(d_loss[0])
    plot_acc_descriminator.append(d_loss[1])


    # Train adversarial model and try to fool discriminator (with incorrect label) 
    # by generating a new batch of noise and assign them labels of real data
    noise = np.random.normal(0,1, size = (batch_size, latent_dim))#-0.10
    labels_gen = np.ones((batch_size))   #*0.9

    # Keep discriminator weights constant while training generator
    discriminator.trainable = False

    # Train GAN (without updating discriminator weights) on new batch of fake images. Assign loss and accuracy to variable
    gan_loss = gan.train_on_batch(noise, labels_gen)
    plot_loss_gan.append(gan_loss[0])
    plot_acc_gan.append(gan_loss[1])


    # Save training status
    # Discriminator and model loss
    training_meta_data[e-1, 0] = d_loss[0]
    training_meta_data[e-1, 1] = gan_loss[0]

    # Discriminator and model accuracy
    training_meta_data[e-1, 2] = d_loss[1]
    training_meta_data[e-1, 3] = gan_loss[1]


    # If at sample interval, print training status and save samples
    if e % sample_interval == 0:
      
        # Print training status
        print("Epoch %d" %e)
        log_mesg = "%d: [Discriminaotr loss: %f, acc: %f]" % (e, d_loss[0], d_loss[1])
        log_mesg = "%s  [GAN loss: %f, acc: %f]" % (log_mesg, gan_loss[0], gan_loss[1])
        print(log_mesg)
        
        # Plot images 
        r, c = 5, 5

        # Create images from the noise (predict the outcome of the noise)
        gen_imgs = generator.predict(noise)

        # Rescale images 0 - 1
        gen_imgs = 0.5 * gen_imgs + 0.5

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i,j].imshow((gen_imgs[cnt].reshape(28, 28)), cmap='gray')
                axs[i,j].axis('off')
                cnt += 1
        plt.show()

# Generate ten images from Gaussian noise using the trained generator from Part 1
noise = np.random.normal(0,1,[10,100])
generated_images = generator.predict(noise)

# Re-scale generated images to lie in [0, 1]
generated_images = 0.5*(generated_images + 1.0)

# Visualize generated noise
r, c = 2, 5
fig, axs = plt.subplots(r, c)
cnt = 0
for i in range(r):
    for j in range(c):
        axs[i,j].imshow((noise[cnt].reshape(10, 10)), cmap='gray')
        axs[i,j].axis('off')
        cnt += 1
plt.show()

# Visualize generated Samples
r, c = 2, 5
fig, axs = plt.subplots(r, c)
cnt = 0
for i in range(r):
    for j in range(c):
        axs[i,j].imshow((generated_images[cnt].reshape(28, 28)), cmap='gray')
        axs[i,j].axis('off')
        cnt += 1
plt.show()

# ASSIGN CLASSES
labels = [4,1,6,4,9,8,1,7,2,9]

# Convert integer labels to one-hot labels 
labels = keras.utils.np_utils.to_categorical(labels, num_classes=10)

# Show classifications
predicted_labels = mnist_classifier.predict(generated_images)

print("Prediction for pre-trained classifier")
print(np.argmax(predicted_labels, axis = 1))

# Evaluate accuracy
accuracy = mnist_classifier.evaluate(generated_images, labels)
print("Accuracy : %.2f%%" %(accuracy[1]*100))





#Import necessary packages
import numpy as np
from keras.datasets import mnist
from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Sequential
import matplotlib.pyplot as plt
from keras import backend as K
import keras

"""#Part 0: Importing and Normalizing Data"""

#Load MNIST data and normalize to [0,1]
(data_train, _), (data_test, _) = mnist.load_data()
data_train = data_train/255.0
data_test = data_test/255.0

"""#Part 1: Deep Fully-Connected AutoEncoder

Answer the following questions: 


1.  We want to predict output values of the intensity of the pixels which are between 0 to 1. Therefore choice of output layer activation function is important. (Open ended reasoning question). (a) Choose 'softmax’ or ‘sigmoid’. Reason why one is preferred over the other.
 

**Although both Sigmoid and Softmax have ouputs in 0 to 1, which is desirable here in the question, but since Softmax makes sure that the sum of all the outputs is 1, which is not required here in the problem, as the pixels need not sum to 1. Sigmoid on the other hand just outputs a number between 0 and 1 and does not require that sum of all outputs is 1, so Sigmoid should be prefered over Softmax in this problem.**
"""

#Reshape training and testing data into 784-dimensional vectors
data_train = np.reshape(data_train, (60000, 784))
print("shape of data_train :", np.shape(data_train))
#
data_test = np.reshape(data_test, (10000, 784))
print("shape of data_test :", np.shape(data_test))

"""**Output Activation: SIGMOID & Cost Function : BINARY COST FUNCTION**"""

#Create autoencoder architecture
def deep_ae():
    model = Sequential()

    # Model Architecture

    # 1st Hidden layer
    # Encoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform",
                    input_dim = 784))

    # 2nd Hidden layer
    # Encoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 3rd Hidden layer
    # Encoded
    model.add(Dense(100,
                    activation = "relu",
                    use_bias = True,
                    name = "Bottle_neck",
                    kernel_initializer = "uniform")) 

    # 4th Hidden layer
    # Decoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 5th Hidden layer
    # Decoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # Decoded
    model.add(Dense(784,
                    activation = "sigmoid",
                    kernel_initializer = "uniform"))


    return model
#Create deep autoencoder graph
deep_ae = deep_ae()
deep_ae.summary()

#Compile model using an appropriate loss and optimizer algorithm
deep_ae.compile(loss = keras.losses.BinaryCrossentropy(),
                    optimizer = 'adam')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
deep_ae_history = deep_ae.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions = deep_ae.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2
deep_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for BCE 
plt.plot(deep_ae_history.history['loss'])
plt.plot(deep_ae_history.history['val_loss'])
plt.title('AE loss vs Epochs - For SIGMOID & BCE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction from the TESTING DATA
n = 10
decoded_imgs = deep_ae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(2,3):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = deep_ae.input # OR You can use XX = deep_ae.layers[0].input
    YY = deep_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (10,10))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
  
# You can also do the SAME as follows using the K function, Both methods produce exactly same results
#for i in range(n):
#  print(" Representation for hidden layer indexed :", l," Using K function:")
#  get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2
#  Xaug1 = data_test[i:i+1]
#  deep_ae_hl = get_hl([Xaug1])[0]
#  deep_ae_hl = np.reshape(deep_ae_hl, (10,10))
#  plt.matshow(deep_ae_hl)
#  plt.show()

"""**Cost Function : MEAN SQUARED ERROR & Output Activation : SIGMOID**"""

#Create autoencoder architecture
def deep_ae():
    model = Sequential()

    # Model Architecture

    # 1st Hidden layer
    # Encoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform",
                    input_dim = 784))

    # 2nd Hidden layer
    # Encoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 3rd Hidden layer
    # Encoded
    model.add(Dense(100,
                    activation = "relu",
                    use_bias = True,
                    name = "Bottle_neck",
                    kernel_initializer = "uniform")) 

    # 4th Hidden layer
    # Decoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 5th Hidden layer
    # Decoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # Decoded
    model.add(Dense(784,
                    activation = "sigmoid",
                    kernel_initializer = "uniform"))


    return model
#Create deep autoencoder graph
deep_ae = deep_ae()
deep_ae.summary()

#Compile model using an appropriate loss and optimizer algorithm
deep_ae.compile(loss = keras.losses.MeanSquaredError(),
                    optimizer = 'adam')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
deep_ae_history = deep_ae.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions = deep_ae.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2
deep_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for Mean Squared Error
plt.plot(deep_ae_history.history['loss'])
plt.plot(deep_ae_history.history['val_loss'])
plt.title('AE loss vs Epochs - SIGMOID & MSE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction
n = 10
decoded_imgs = deep_ae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(2,3):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = deep_ae.input
    YY = deep_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (10,10))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
    print("\n")

"""**BONUS : Using Linear Output Activation and Binary Cross Entropy**"""

#Create autoencoder architecture
def deep_ae():
    model = Sequential()

    # Model Architecture

    # 1st Hidden layer
    # Encoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform",
                    input_dim = 784))

    # 2nd Hidden layer
    # Encoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 3rd Hidden layer
    # Encoded
    model.add(Dense(100,
                    activation = "relu",
                    use_bias = True,
                    name = "Bottle_neck",
                    kernel_initializer = "uniform")) 

    # 4th Hidden layer
    # Decoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 5th Hidden layer
    # Decoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # Decoded
    model.add(Dense(784,
                    activation = "linear",
                    kernel_initializer = "uniform"))
    

    return model
#Create deep autoencoder graph
deep_ae = deep_ae()
deep_ae.summary()

#Compile model using an appropriate loss and optimizer algorithm
deep_ae.compile(loss = keras.losses.BinaryCrossentropy(),
                    optimizer = 'adam')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
deep_ae_history = deep_ae.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions = deep_ae.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2
deep_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for LINEAR activation and Binary Cross Entropy
plt.plot(deep_ae_history.history['loss'])
plt.plot(deep_ae_history.history['val_loss'])
plt.title('AE loss vs Epochs - For LINEAR Act. & BCE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction
n = 10
decoded_imgs = deep_ae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(2,3):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = deep_ae.input
    YY = deep_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (10,10))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
    print("\n")

"""**BONUS : Using Linear Output Activation and Mean Squared Error**"""

#Create autoencoder architecture
def deep_ae():
    model = Sequential()

    # Model Architecture

    # 1st Hidden layer
    # Encoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform",
                    input_dim = 784))

    # 2nd Hidden layer
    # Encoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 3rd Hidden layer
    # Encoded
    model.add(Dense(100,
                    activation = "relu",
                    use_bias = True,
                    name = "Bottle_neck",
                    kernel_initializer = "uniform")) 

    # 4th Hidden layer
    # Decoded
    model.add(Dense(200,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # 5th Hidden layer
    # Decoded
    model.add(Dense(400,
                    activation = "relu",
                    use_bias = True,
                    kernel_initializer = "uniform"))
    
    # Decoded
    model.add(Dense(784,
                    activation = "linear",
                    kernel_initializer = "uniform"))
    

    return model
#Create deep autoencoder graph
deep_ae = deep_ae()
deep_ae.summary()

#Compile model using an appropriate loss and optimizer algorithm
deep_ae.compile(loss = keras.losses.MeanSquaredError(),
                    optimizer = 'adam')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
deep_ae_history = deep_ae.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions = deep_ae.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2
deep_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for LINEAR activation and Mean Squared Error
plt.plot(deep_ae_history.history['loss'])
plt.plot(deep_ae_history.history['val_loss'])
plt.title('AE loss vs Epochs - For LINEAR Act. & MSE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction
n = 10
decoded_imgs = deep_ae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(2,3):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = deep_ae.input
    YY = deep_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (10,10))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
    print("\n")

"""Answer the following questions: 


1.  Question 2c: BONUS [reasoning question]: Pair the output layer activation and loss function which performs better together. Linear, sigmoid, Binary cross entropy and Mean Square error
**For Linear Activation & Binary Cross Entropy - training loss: 0.1774 - testing loss: 0.1740**

**For Linear Activation & Mean Squared Error - training loss: 0.0060 - testing loss: 0.0060** 

**For Sigmoid Activation & Binary Cross Entropy - training loss: 0.0758 - testing loss: 0.0769**

**For Sigmoid Activation & Mean Squared Error - training loss: 0.0048 - testing loss: 0.0051**
 
**Looking at the output images in the 4 cases, Sigmoid activation and BCE produces the most clear output images, which are closest in resembelence to the original image. We also note that Sigmoid-MSE also produce very good images and it is hard to distinguish between sigmoid-mse vs sigmoid-bce. But using sigmoid-bce ensures the good properties of the gradient (non saturation, consistency) of the cost function, hence sigmoid-bce is to be prefered.**

**If using the Linear output activation function, then it produces better images when used with the MSE error cost function, rather than when used along with BCE loss function.**


2.  Question 5: Observe the output images and comment Which loss function is better and why?
**FOR SIGMOID ACTIVATION : It is very difficult to compare and distinguish which cost function bce or mse does better for sigmoid. On magnifying the first 10 output images obtained from the 2 cost functions, it is noted that in BCE the ouput images indexed at 8, 9, and 10 are slightly more better than the ones obtained via the MSE.**

**For Linear : Clearly from the output images, MSE is doing better than BCE**

3.  Question 6: If we were to predict pixels values [0 to 255] directly at the output of last layer. Should there be an activation function in last later?  If yes, which activation function and why?,  If No, reason why?
**The only reason we used the Sigmoid activation at the output layer, was to convert the outputs to lie in 0 to 1. So if we normalize the data by deviding by 255, and want the ouputs in [0,1], then SIGMOID is used.**

**But if we do not want the outputs in [0,1], and want to output the pixel values in [0,255], then WE CAN NOT USE SIGMOID, because sigmoid outputs values in [0,1]. Moreover, in this case we DO NOT NEED any non linear activation function at the output layer, as we do not want to alter the ouput obtained after the final linear transformation using W^t X + b, which is directly predicting the pixel values in [0,255] using MSE cost function.**

QUESTION ADDED BY PROF. ON PIAZZA: The question in project 2 on comparing the results of binary cross-entropy and MSE is an open question. We want your comments not only on the observed images but also on the generality of applying these losses (and how do you think binary cross-entropy works in this setting, i.e., how is it implemented).

**If the input values are in the range [0,1], then SIGMOID is acceptable, else we need to use something like a linear activation function, which is equivalent to having no non linear activation.**

**If the input values are in [0,1], then BCE is acceptable. In this case BCE is applied to each of the neurons in the last layer and thus results in multiple values in [0,1]. Else if the inputs are not in [0,1], then we use cost functions like MSE, which by the way can also be used when inputs are in [0,1].**

#Part 2: Deep Convolutional AutoEncoder
"""

#Reshape data into 2-D signals and account for grayscale channel in each image
#Load MNIST data and normalize to [0,1]
(data_train, _), (data_test, _) = mnist.load_data()
data_train = data_train/255.0
data_test = data_test/255.0
data_train = np.reshape(data_train, (60000, 784))
print("shape of data_train :", np.shape(data_train))
#
data_test = np.reshape(data_test, (10000, 784))
print("shape of data_test :", np.shape(data_test))

data_train = np.reshape(data_train, (60000, 28,28,1))
data_test = np.reshape(data_test, (10000, 28,28,1))
#for i in range(60000):
#  print(np.shape(data_train[i]))
#for j in range(10000):
#  data_test[j] = np.reshape(data_test[j], (28,28,2))

#Create Convolutional AutoEncoder Architecture
def cae():
    model = Sequential()

    #FILL THIS IN WITH MODEL ARCHITECTURE
    # 1st Hidden layer 
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     padding = "same",
                     use_bias = True,
                     input_shape = (28,28,1)))

    # 2nd Hidden Layer
    model.add(MaxPooling2D(pool_size = (2,2),
                          padding = "same"))
    
    # 3rd Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))
       
    # 4th Hidden layer
    model.add(MaxPooling2D(pool_size=(2,2),
                           name = "bottle_neck",
                           padding = "same"))

    # 5th Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 6th Hidden Layer
    model.add(UpSampling2D((2,2)))

    # 7th Hidden layer
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 8th Hdden layer
    model.add(UpSampling2D((2,2)))

    # Output layer reconstruction
    model.add(Conv2D(1,
                      (3,3) ,
                      activation = "sigmoid",
                      use_bias = True,
                      padding = "same"))

    return model

#Create deep autoencoder graph
conv_ae = cae()
conv_ae.summary()


#Compile model using an appropriate loss and optimizer algorithm
conv_ae.compile(loss = keras.losses.BinaryCrossentropy(),
                    optimizer = 'adam')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
conv_ae_history = conv_ae.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions = conv_ae.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([conv_ae.layers[0].input], [conv_ae.layers[3].output])  # The fourth hidden layer are indexed at 3
conv_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for SIGMOID activation and BINARY CROSS ENTROPY
plt.plot(conv_ae_history.history['loss'])
plt.plot(conv_ae_history.history['val_loss'])
plt.title('CONV - AE loss vs Epochs - For Sigmoid Act. & BCE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction
n = 10
decoded_imgs = conv_ae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations for Bottleneck layer
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(3,4):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = conv_ae.input
    YY = conv_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (28,14))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
    print("\n")

"""**Deep Convolutional AutoEncoder : SIGMOID Activation & Mean Squared Error Loss Function**"""

#Create Convolutional AutoEncoder Architecture
def cae():
    model = Sequential()

    #FILL THIS IN WITH MODEL ARCHITECTURE
    # 1st Hidden layer 
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     padding = "same",
                     input_shape = (28,28,1)))

    # 2nd Hidden Layer
    model.add(MaxPooling2D(pool_size = (2,2),
                          padding = "same"))
    
    # 3rd Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     padding = "same"))
       
    # 4th Hidden layer
    model.add(MaxPooling2D(pool_size=(2,2),
                           name = "bottle_neck",
                           padding = "same"))

    # 5th Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     padding = "same"))

    # 6th Hidden Layer
    model.add(UpSampling2D((2,2)))

    # 7th Hidden layer
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     padding = "same"))

    # 8th Hdden layer
    model.add(UpSampling2D((2,2)))

    # Output layer reconstruction
    model.add(Conv2D(1,
                      (3,3) ,
                      activation = "sigmoid",
                      padding = "same"))

    return model

#Create deep autoencoder graph
conv_ae_mse = cae()
conv_ae_mse.summary()


#Compile model using an appropriate loss and optimizer algorithm
conv_ae_mse.compile(loss = keras.losses.MeanSquaredError(),
                    optimizer = 'adadelta')

#Train the model and assign training meta-data to a variable
num_epochs = 150
batch_size = 1024
conv_ae_mse_history = conv_ae_mse.fit(data_train, data_train,
                                    validation_data = (data_test, data_test),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)

#Calculate the reconstructions of the testing set (output of autoencoder on test set)
reconstructions_mse = conv_ae_mse.predict(data_test)


#Obtain encoder representation of data
get_hl = K.function([conv_ae_mse.layers[0].input], [conv_ae_mse.layers[3].output])  # The fourth hidden layer are indexed at 3
conv_ae_hl = get_hl([data_test])[0]

#Plot loss vs epoch for SIGMOID activation and MEAN SQUARED ERROR
plt.plot(conv_ae_mse_history.history['loss'])
plt.plot(conv_ae_mse_history.history['val_loss'])
plt.title('CONV - AE loss vs Epochs - For Sigmoid Act. & MSE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 images, their hidden layer representations, and their reconstructions
# Showing samples of 10 images and their reconstruction
n = 10
decoded_imgs = conv_ae_mse.predict(reconstructions_mse)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Printing their hidden layer representations for Bottleneck layer
print(" Printing the hidden layer representations :")
print (" ")
from keras.models import Model
for i in range(n):
  print(" For data_test image indexed :", i)
  for l in range(3,4):
    print(" Representation for hidden layer indexed :", l)
    XX = []
    YY = []
    XX = conv_ae.input
    YY = conv_ae.layers[l].output
    new_model = Model(XX,YY)
    Xaug = data_test[i:i+1]
    Xresult = new_model.predict(Xaug)
    Xresult = np.reshape(Xresult, (28,14))
    plt.matshow(Xresult)
    #plt.matshow(Xresult, cmap = 'viridis')
    plt.show()
    print("\n")

"""Answer the following questions: 


1.  Question 4: Observe the output images, Which loss function is better and why?
**I would want to note here that while using sigmoid-MSE in this part, along with 'adam' optimizer, the output images on the test data were all blank, so I changed the optimizer from adam to adadelta for runing sigmoid-MSE case. With this change the results improved.**

**Here also, similar to part 1, output images for both the cases are very similar and equally good, so it is difficult to distinguish between which function is better. Possiblly if we run it for more iterations we could be able to decide which is better.**

**Just on the basis of the first 10 images after 150 iterations, 10th image in BCE is more accurate than the 10th image from MSE, while all others seems equally good.**

#Part 3: Denoising AutoEncoder
"""

#Inject noise into testing data
noise_factor = 0.25
data_train_noisy = data_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_train.shape)
data_test_noisy = data_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_test.shape)

#Clip to stay within valid (normalized) pixel range
data_train_noisy = np.clip(data_train_noisy, 0., 1.)
data_test_noisy = np.clip(data_test_noisy, 0., 1.)

#Reshape data to comply with input of denoising autoencoder
data_train = np.reshape(data_train, (60000, 28,28,1))
data_train_noisy = np.reshape(data_train_noisy, (60000, 28,28,1))

data_test = np.reshape(data_test, (10000, 28,28,1))
data_test_noisy = np.reshape(data_test_noisy, (10000, 28,28,1))

#Show samples of 10 original images and their corrsponding noisy counterparts from the training set
n = 10
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_train[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY NOISY
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(data_train_noisy[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

"""**Create denoising autoencoder architecture: SIGMOID AND BCE**"""

#Create denoising autoencoder architecture
def dae():
    model = Sequential()

    #FILL THIS IN WITH MODEL ARCHITECTURE
    # 1st Hidden layer 
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     padding = "same",
                     use_bias = True,
                     input_shape = (28,28,1)))

    # 2nd Hidden Layer
    model.add(MaxPooling2D(pool_size = (2,2),
                          padding = "same"))
    
    # 3rd Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))
       
    # 4th Hidden layer
    model.add(MaxPooling2D(pool_size=(2,2),
                           name = "bottle_neck",
                           padding = "same"))

    # 5th Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 6th Hidden Layer
    model.add(UpSampling2D((2,2)))

    # 7th Hidden layer
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 8th Hdden layer
    model.add(UpSampling2D((2,2)))

    # Output layer reconstruction
    model.add(Conv2D(1,
                      (3,3) ,
                      activation = "sigmoid",
                      use_bias = True,
                      padding = "same"))

    return model
  

#Create graph
dae = dae()
dae.summary()
  
#Compile model using an appropriate loss and optimizer algorithm
dae.compile(loss = keras.losses.BinaryCrossentropy(),
                    optimizer = 'adam')

num_epochs = 150
batch_size = 1024
dae_history = dae.fit(data_train_noisy, data_train_noisy,
                                    validation_data = (data_test_noisy, data_test_noisy),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)


#Generate denoised versions of noisy inputs
reconstructions = dae.predict(data_test_noisy)

#Plot loss vs epoch for SIGMOID activation and Binary Cross Entropy FOR DAE
plt.plot(dae_history.history['loss'])
plt.plot(dae_history.history['val_loss'])
plt.title('DAE loss vs Epochs - For Sigmoid Act. & BCE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 original images, their noisy counterparts from the testing set
n = 10
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY NOISY
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(data_test_noisy[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Showing the first 10 noised & their de-noised version from the testing set
n = 10
decoded_imgs = dae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test_noisy[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

"""**Create denoising autoencoder architecture : SIGMOID AND MSE**

"""

#Create denoising autoencoder architecture
def dae():
    model = Sequential()

    #FILL THIS IN WITH MODEL ARCHITECTURE
    # 1st Hidden layer 
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     padding = "same",
                     use_bias = True,
                     input_shape = (28,28,1)))

    # 2nd Hidden Layer
    model.add(MaxPooling2D(pool_size = (2,2),
                          padding = "same"))
    
    # 3rd Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))
       
    # 4th Hidden layer
    model.add(MaxPooling2D(pool_size=(2,2),
                           name = "bottle_neck",
                           padding = "same"))

    # 5th Hidden layer
    model.add(Conv2D(8,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 6th Hidden Layer
    model.add(UpSampling2D((2,2)))

    # 7th Hidden layer
    model.add(Conv2D(16,
                     (3,3),
                     activation = "relu",
                     use_bias = True,
                     padding = "same"))

    # 8th Hdden layer
    model.add(UpSampling2D((2,2)))

    # Output layer reconstruction
    model.add(Conv2D(1,
                      (3,3) ,
                      activation = "sigmoid",
                      use_bias = True,
                      padding = "same"))

    return model
  

#Create graph
dae = dae()
dae.summary()
  
#Compile model using an appropriate loss and optimizer algorithm
dae.compile(loss = keras.losses.MeanSquaredError(),
                    optimizer = 'adam')

num_epochs = 150
batch_size = 1024
dae_history = dae.fit(data_train_noisy, data_train_noisy,
                                    validation_data = (data_test_noisy, data_test_noisy),
                                    epochs = num_epochs,
                                    batch_size = batch_size,
                                    shuffle = True)


#Generate denoised versions of noisy inputs
reconstructions = dae.predict(data_test_noisy)

#Plot loss vs epoch for SIGMOID activation and MSE FOR DAE
plt.plot(dae_history.history['loss'])
plt.plot(dae_history.history['val_loss'])
plt.title('DAE loss vs Epochs - For Sigmoid Act. & MSE')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test','upperleft'])
plt.show()

#Show samples of 10 original images, their noisy counterparts from the testing set
n = 10
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY NOISY
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(data_test_noisy[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

# Showing the first 10 noised & their de-noised version from the testing set
n = 10
decoded_imgs = dae.predict(reconstructions)
plt.figure(figsize=(20,4))
for i in range(n):
  # DISPLAY ORIGINAL
  ax = plt.subplot(2,n,i+1)
  plt.imshow(data_test_noisy[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # DISPLAY RECONSTRUCTED
  ax = plt.subplot(2,n,i+1+n)
  plt.imshow(decoded_imgs[i].reshape(28,28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)  
plt.show()

"""In the PART3, the output images are more clear when we used SIGMOID with MSE loss function."""